#  【论文速读】|大语言模型在代码漏洞分析中的应用：一项概念验证研究  
原创 知识分享者
                    知识分享者  安全极客   2026-01-22 09:35  
  
![](https://mmbiz.qpic.cn/mmbiz_jpg/vWuBpewLia8QmTLhv0jB8GS6Wtic69pG44V8Gib7ccD3FZolnOVkdOPafA3YULibw9S5AEkdO8sstRLGNFVDj7SgRg/640?wx_fmt=jpeg&from=appmsg "")  
  
**基本信息**  
  
  
原文标题：LLMs in Code Vulnerability Analysis: A Proof of Concept  
  
原文作者：Shaznin Sultana, Sadia Afreen, Nasir U. Eisty  
  
作者单位：Ohio University（Shaznin Sultana）、University of Cincinnati（Sadia Afreen）、University of Tennessee（Nasir U. Eisty）  
  
关键词：Large Language Models、Code Vulnerability、CVE、CWE、软件安全、漏洞检测、自动修复、fine-tuning、prompt learning  
  
原文链接：https://arxiv.org/pdf/2601.08691  
  
开源代码：暂无  
  
  
**论文要点**  
  
  
论文简介：  
  
本文聚焦于现代软件安全领域，旨在应对传统漏洞分析手段面对海量复杂代码时在效率和准确性层面的重大瓶颈。随着大语言模型（LLMs）在文本与代码分析上的快速发展，研究者希望探索其在代码安全自动化中的应用价值。本文提出将代码专业型与通用型的大语言模型引入软件安全自动化分析全流程，涵盖漏洞检测、风险（严重性和访问复杂度）预测及自动修复四大核心任务，通过系统性实验，比对fine-tuning（微调训练）与基于prompt的zero-shot、few-shot等不同范式。在两个权威C/C++漏洞数据集（Big-Vul、Vul-Repair）上，选取五组领先开源模型进行了多维性能评测，涵盖F1、CodeBLEU、CodeBERTScore等多项指标。结果表明，fine-tuning在所有任务和模型下均显著优于纯提示范式，代码特定模型在复杂场景中表现出微弱优势，但通用模型在多数情境下同样有效。论文还揭示了漏洞修复任务中现有代码相似度评测指标的不足，并提出进一步研究的方向。本文通过系统性实证，丰富了开源LLMs在软件安全领域的方案评估与应用参考。  
  
研究目的：  
  
本研究着眼于现有自动化软件安全工具易受限于检测覆盖、语言适应性及可用性的难题，而大语言模型的涌现为软件安全流程智能化赋能提供了新机遇。然而，LLMs在代码漏洞分析全流程中的适用性、有效性及投入成本等问题尚缺乏体系化、定量化的比较。本文旨在全面评估并明晰开源通用型与代码特定型LLMs在代码安全四大关键任务（检测、严重性预测、访问复杂度分类、自动修复）下各自的性能表现，系统性比对fine-tuning与prompt learning等不同方法学在不同任务中的能力边界与资源消耗，为实际软件安全场景中的LLMs模型选择与部署提供参考依据。  
  
研究贡献：  
- 本文系统评估了代码专业型与通用型大语言模型在漏洞分析场景下的性能表现，明确代码专业化模型在部分环节的细微优势与通用模型的广泛实用性。  
  
- 对比了基于prompt的zero-shot/few-shot与任务专用微调（fine-tuning）两类主流范式，系统揭示微调方法在复杂任务下的显著性能提升与资源消耗状况。  
  
- 全面探索并实测了多款开源LLMs（涵盖Llama、Gemma、Qwen、Mistral、Deepseek等家族）在漏洞检测、风险等级评估及自动修复任务的指标表现，强有力地验证了开源模型对专有产品的可行性替代。  
  
- 论文所用全部代码及分组数据集已公开，为同行复现与深度应用研究提供便利。  
  
  
  
  
**引言**  
  
  
现代软件系统的庞杂性和开放性决定了安全威胁的多样和隐蔽，给漏洞检测带来巨大挑战。传统软件安全分析工具如静态分析器常面临覆盖受限、对多语言适应性差以及准确率不足等主要瓶颈。具体到开发者实践，这些工具容易误报和漏报、配置繁琐，且实际使用门槛较高，难以胜任对大规模、复杂代码库的全面手工审查。随着人工智能，尤其是大语言模型（LLMs）在文本与代码理解上的巨大突破，学界业界开始关注其在软件工程各环节（如代码生成、补全、缺陷检测等）中的引领效应，并逐步探索LLMs应用于安全性分析的边界与新机遇。此前大部分研究聚焦于漏洞检测与修复的初步能力，但是在漏洞属性分析、风险定级等细粒度环节、不同类型模型的优势对比，以及模型能力增长与成本平衡等问题上，仍缺乏“横向贯通”的定量实证研究。此外，LLMs在缺乏人类先验时是否具备足够的实际工程适应力，以及业界所关心的安全性、稳定性、部署经济性等问题也亟需数据支撑。  
  
在此背景下，本文提出以软件漏洞管理（Software Vulnerability Management，SVM）为流程范式，以开源LLMs为核心，系统评估代码专业型与通用型模型在漏洞检测、风险（严重性和访问复杂度）预测、自动修复四大分任务的效果。研究特意构建跨模型（精挑五组代码-通用模型）、跨任务、跨方法范式（fine-tuning、zero-shot、few-shot）、跨数据集（Big-Vul、Vul-Repair）的大规模实验矩阵设计，重点关注：1）微调和prompt方法的效果与成本平衡；2）代码专业化模型与通用模型在不同场景下的表现交互；3）不同模型组合在各项任务下的最佳实践，以及4）现有代码修复评测指标是否客观反映安全性。本研究在推动LLMs系统进入实用化阶段、为自动化软件安全实践提供理论依据和技术路线等方面具有重要意义。  
  
  
**相关工作**  
  
  
近年来，伴随大语言模型能力不断突破，基于LLMs的代码分析与安全研究迅速发展。最早一批相关工作尝试对现有NLP模型（如BERT）进行结构修改，用于漏洞检测或与图网络等结合实现多视角特征编码，或围绕GPT系列模型开展基于上下文提示的错误识别。继检测任务后，漏洞的描述、定位、修复及归因分析等环节也涌现出相应的深度学习方法，并逐渐强调多任务协同、多角度特征挖掘。例如，细化的修复任务通过强化学习、结构化输入标记（如显式的BUG标记）显著提升修复准确率，且探讨多模型协同和数据驱动创新对漏洞检测修复能力的倍增效应。  
  
Prompt工程同样被证实在调动LLMs现有知识、提升零样本与少样本能力方面卓有成效。部分研究针对不同任务设计链式思考（CoT）提示策略、利用检索增强构建动态提示上下文，或专门针对去编译代码进行微调。混合范式如IRIS将静态分析与LLMs联合，在提升漏洞发现能力的同时，强调模型与工程工具的互补关系。此外，大量研究关注LLMs和传统静态分析工具的对比实验，发现前者在准确率方面逐步显现优势，但在开发者信任、解释性等方面仍有提升空间。  
  
总体来看，现有研究已初步验证LLMs在漏洞检测、修复等核心流程的可行性和局部优势，但对多任务、多模型和多方法范式的横向系统对比尚不充分，对实际工程落地的任务细节、评测标准一致性等也亟需更多定量实证。本研究立足此空白，推进LLMs赋能软件安全的领域落地和方法体系创新。  
  
  
**研究方法**  
  
  
本研究围绕LLMs在漏洞检测、风险评估与自动修复全流程的效能展开多维对比实验。模型选择涵盖五大主流开源家族（Llama、Gemma、Qwen、Mistral、DeepSeek）中的代码特定与通用版本（共10款），参考多份公开权威榜单遴选最具代表性的开源模型，并对应推理/训练接口实现了最大化资源复用和实验一致性。其中，模型加载主要依赖Unsloth与HuggingFace工具链，支持4-bit量化与大Token窗口；fine-tuning环节采用LoRA PEFT实现参数高效微调，设置合理的超参数以平衡计算资源消耗与收敛效果。  
  
数据集选用Big-Vul和VulRepair，分别覆盖上万规模的被标记C/C++漏洞与修复实例，并对样本类别均衡、标注质量、上下文补充等进行数据清洗与预处理。Big-Vul用于前三类任务（检测、严重性、复杂度预测），通过欠采样技术实现类别平衡；VulRepair用于第四类fix generation任务，直接继承显式bug区段标记以便模型对齐。  
  
任务定义分为四大类：1）检测模型直接判断代码片段是否存在安全漏洞及其类型，要求对主流安全问题拥有概念识别和特征抽象能力；2）严重性预测参照CVSS国际标准，以分数映射至高、中、低三级，考查模型对安全影响评估的判别能力；3）访问复杂度分类利用CWSS标准，要求模型判断攻击者渗透漏洞的技术难度；4）修复生成则主动产出安全修复补丁，需兼顾修复的安全性和合理性。每项任务均分别基于fine-tuning、zero-shot和few-shot三种主流策略进行能力对比，prompt工程内容围绕实际代码上下文、漏洞类型、描述和CWE ID等关键信息构建，few-shot示例选自不同类别边界，确保最大化模型泛化能力。  
  
![](https://mmbiz.qpic.cn/mmbiz_png/vWuBpewLia8Ryf3p4X5mVbRicpRjKcy8dLNbIZl9HqmajmAoTy3yljsb0fdJ9tKAIz7nUAEzsb9PuPrPWPiaTFA0Q/640?wx_fmt=png&from=appmsg "")  
  
评估指标分层设定：检测与分类任务使用F1为主，兼顾精度与召回，修复任务则综合使用CodeBERTScore、CodeBLEU、ROUGE-L、BLEU-4与ChrF，强调语义匹配、句法与片段级准确性。在结果提取方面，针对不同任务和模型的输出格式设计专用正则表达式自动解析，确保评测自动化与一致性。  
  
所有实验在GPU资源受限的环境下调优，控制变量、最大输入长度、少样本提示数等都做了标准化设定。论文还对实验流程、超参数设置、评测流程和后处理等细节进行了全面梳理，强化了复现性和实验数据可信度。  
  
  
**结果与分析**  
  
  
实验结果围绕四大研究问题（RQ）系统展开，细致揭示不同模型、任务与方法范式组合下的表现异同及成因分析。  
  
1. Fine-tuning vs prompt learning（RQ1）    
  
在基础漏洞检测任务中，所有模型在经过fine-tuning训练后均显著优于zero-shot和few-shot提示范式。F1分数的提升不仅幅度大且具有一致性，最高可达93%（DeepSeek R1），而prompt方式通常在60%-76%之间浮动。特别值得注意的是few-shot并未像预期那样显著高于zero-shot，显示prompt导向下LLMs的即兴学习能力受到语义复杂度和样本信息压缩的显著限制。微调方法虽然资源消耗大，但对任务适应能力提升最为显著。  
  
![](https://mmbiz.qpic.cn/mmbiz_png/vWuBpewLia8Ryf3p4X5mVbRicpRjKcy8dL4xgAq01BhqX0f7eUweKplhiaicEsvJfwjUCvRfRINgf4FgqlK6ibcwEXg/640?wx_fmt=png&from=appmsg "")  
  
2. 代码特定模型与通用模型对比（RQ2）    
  
实验表明，代码专业型模型在fine-tuning下于检测、严重性等复杂任务环节稍有优势，但并未对所有情景产生压倒性胜利。在prompt场景中，通用模型往往因预训练广泛语境、泛化强而表现更为平衡，甚至在部分任务和组合中超过专业模型。以DeepSeek家族为例，通用R1版本在所有子任务及方法下均超越特定的代码版，表明模型架构及预训练规模的基础实力对实际效果的影响极大。少样本情况下，代码专业模型适合复杂任务，简单任务反而不如通用模型，提示任务复杂度和模型预训练分工之间关联性强烈。  
  
![](https://mmbiz.qpic.cn/mmbiz_png/vWuBpewLia8Ryf3p4X5mVbRicpRjKcy8dLJ6ibEQ72yibJJzHJoLcC0tTJN1FD2wcibBr16plENibWSQmcKYCsYvZTQg/640?wx_fmt=png&from=appmsg "")  
  
3. 模型家族综合对比（RQ3）    
  
对各模型组pair的平均F1表现分析，Llama与DeepSeek组合展现出最稳健的能力，无论在fine-tuning还是prompt设置下均列前茅。Mistral群体的单体效果突出但与其对应代码版搭配整体排名略有下滑。整体来看，开源主流LLMs在漏洞分析基本任务中有望取代专有产品，选择正确的模型组合和任务范式更能显著提升效率和准确性。  
  
![](https://mmbiz.qpic.cn/mmbiz_png/vWuBpewLia8Ryf3p4X5mVbRicpRjKcy8dLQAu5n1xgQiclMs7SM1iaofvDjjKcwy9XYU8xiajicYUh8s0bwib93xv8svg/640?wx_fmt=png&from=appmsg "")  
  
4. 修复任务评测指标充分性（RQ4）    
  
自动修复任务中，fine-tuned模型在各类相似度指标上均显著领先。值得注意的是，传统BLEU、CodeBLEU等基于词法的指标对复杂C语言修复的判分显著偏低，而语义驱动的CodeBERTScore、ROUGE-L得分则能更好反映实际提升，揭示单一、静态的参考答案不足以充分衡量修复有效性和多样性。当前评估方法更适合语法简洁语言如Python，C类代码的修复灵活性与安全性之间的评判仍需执行级、专家共识多重验证。Zero-shot及few-shot任务下基准指标普遍偏低，进一步验证了微调对于语义和结构深度对齐的重要意义。  
  
![](https://mmbiz.qpic.cn/mmbiz_png/vWuBpewLia8Ryf3p4X5mVbRicpRjKcy8dLrZMOAbAVibBTQvMzPpmga3bIdtVVxDpn5aDm2S7zrtqtFoEiatPAE7KQ/640?wx_fmt=png&from=appmsg "")  
  
  
**讨论与局限性**  
  
  
本文的系统性实证研究揭示了LLMs在赋能软件安全全流程中的真正潜力与能力边界，但也存在一系列需要深入探索与现实考量的问题。首先，部分任务如zero-与few-shot在输出格式、边界样本处理等场景下表现出不稳定性，不同模型之间对于输入格式的鲁棒性差异明显，影响实际工程落地时的自动化程度和可靠性。数据集本身也存在如标注噪音、无效样本等共性缺陷，这对于zero-shot等“弱指导”场景极易引入错判误差，说明未来更高质量、更高信噪比的数据集构建依然是提升整体水平的前提。  
  
此外，大模型的指令微调通常会生成繁冗输出并拉长推断周期，超出实际生产系统的响应预期和管理成本。所有实验主要针对C/C++代码，对内存安全语言（如Rust、Go）等更高安全需求领域的推广和通用性还需要进一步验证；部分任务的多语言间泛化能力也尚未在本研究框架下验证。此外，现有代码修复评测指标多为静态匹配，对实际安全性和可用性缺乏物理/功能验证闭环。未来可引入动态测试、代码执行与专家辅助评议等多元手段，实现更加客观、全面的自动化安全修复评价。  
  
  
**论文结论**  
  
  
本文首次以全流程、横向对比视角，系统评估了开源大语言模型（LLMs）在代码漏洞检测、风险评估与自动修复多任务场景下的效能边界。实验证明，fine-tuning依然是提升模型适应场景和任务能力的最有效手段，但其资源消耗较高，需要部署场景作合理权衡。代码专业型模型仅在零散高难场景下具备边际优势，通用型模型在广泛任务中足以胜任，模型选择需结合具体应用环境和资源状况灵活调整。修复任务现存的静态匹配评测方法亟需革新，强调语义、功能与安全性多元交融的评价体系。开源LLMs凭借微调和正确的任务范式，已具备完全替代专有模型的潜力。未来工作将聚焦于多语言扩展、模型集成与执行级修复评测等领域，进一步提升自动化安全管理的智能化水平与可信度。  
  
-End-  
  
[](https://mp.weixin.qq.com/s?__biz=MzkzNDUxOTk2Mw==&mid=2247495405&idx=1&sn=67249648d5c312b5c178b23b077d28f3&scene=21#wechat_redirect)  
  
![图片](https://mmbiz.qpic.cn/mmbiz_png/vWuBpewLia8R7Rm0KL55HCcIiasO8JJ7IibXzYxx3losWVb2eddxdClACzWxWtQLwl0wkAl1ZLibcESVWvx5dCeibtQ/640?wx_fmt=other&wxfrom=5&wx_lazy=1&tp=webp#imgIndex=2 "")  
  
  
![图片](https://mmbiz.qpic.cn/mmbiz_png/vWuBpewLia8QRqLMRicZIN6VJg0ue41W1HVSmDpDqkj86j5SNicNE3X5KkPgcdv1ZmxM7FXrFUdkBes8dpos7d27w/640?wx_fmt=other&wxfrom=5&wx_lazy=1&tp=webp#imgIndex=4 "")  
  
