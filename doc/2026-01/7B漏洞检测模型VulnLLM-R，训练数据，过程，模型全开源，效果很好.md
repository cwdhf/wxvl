#  7B漏洞检测模型VulnLLM-R，训练数据，过程，模型全开源，效果很好  
原创 孙志敏
                    孙志敏  AI与安全   2026-01-24 02:00  
  
上一篇我们看了以色列Novee的安全小模型，4B表现出非常好的效果，但由于未开源，能获取的信息有限。近期，一篇全面介绍漏洞检测模型的论文发表，从论文看，通过在 Python、C/C++ 和 Java 等语言的最先进的数据集上进行大量实验，证明了 VulnLLM-R 的有效性和效率均优于最先进的静态分析工具以及开源和商业的大型推理模型。这效果很不错，值得研究一下。  
  
  
01  
  
关于论文  
  
  
  
论文没有明确说明发布单位，开源在ucsb目录下。Dawn Song在其中，安全圈里的大名人，不了解的可以去查查她的简历。其它名字，看上去也都是国人。  
  
  
![](https://mmbiz.qpic.cn/sz_mmbiz_png/rhmRSVBNbicpQscUKCBoKtGjiaiaBatb6cxpIzgs20dkibV4ILTBJyicqsc8dJ7CBxyicnXPop5EH79v3VEs8NCmyiaqw/640?from=appmsg "")  
![]( "")  
![]( "")  
![]( "")  
  
  
02  
  
模型效果  
  
  
  
如下图所示，纵轴表示模型性能，横轴表示模型参数规模。可以看到，VulnLLM-R 在漏洞检测任务上实现了性能与模型规模之间的显著优化：在与多种通用超大规模模型的对比中，其整体检测性能达到了当前最先进水平，同时具备更高的参数效率。  
  
简单说，VulnLLM-R 仅使用 7B 参数规模，就在多个指标上超过了许多参数量远大于它的通用大模型，充分体现了专用模型在漏洞检测场景中的优势。  
  
![](https://mmbiz.qpic.cn/sz_mmbiz_png/rhmRSVBNbicpQscUKCBoKtGjiaiaBatb6cxdX3LOMx9rv9rm9EMtDDGZPnwj4MiabdbchILgkDkDD9ZLcJSFYepV7w/640?from=appmsg "")  
![]( "")  
![]( "")  
![]( "")  
  
  
03  
  
训练数据  
  
  
  
在训练数据的选择上，我们主要遵循两个原则：  
漏洞类型覆盖充分  
，以及  
代码规模具有多样性  
。  
  
首先是漏洞类型覆盖。我们希望模型能够理解不同 CWE 漏洞在不同语言中的表现形式，因此训练数据中同时包含了使用多种编程语言编写的  
易受攻击代码  
，以及对应的  
安全代码  
。其中，安全代码并不是随意选取的，而是直接来自漏洞修复后的补丁版本，这样可以帮助模型更清楚地区分“有问题的写法”和“正确的写法”。此外，我们还引入了一部分普通、不涉及漏洞的代码片段，用于让模型学习常见的代码结构和编程习惯，避免把“不常见写法”误判为漏洞。  
  
其次是代码规模的多样性。现实中的漏洞既可能出现在几行代码的小函数里，也可能隐藏在跨多个函数、甚至多个文件的复杂逻辑中。为了覆盖这种差异，我们在训练集中刻意引入了不同规模的代码样本，并使用代码行数（LoC）作为衡量标准。  
  
具体来说，我们从   
Juliet 1.3 数据集  
 中选取了大量结构相对简单、代码较短的函数，用于覆盖基础漏洞模式；同时，从   
PrimeVul 数据集  
 中引入了一批代码规模更大、逻辑更复杂的函数，以提升模型处理真实项目代码的能力。此外，我们还纳入了   
ARVO 数据集（2024 年 5 月版本）  
 中的样本，其中一些漏洞涉及多个函数甚至多个源文件。例如，ARVO-15374 这个漏洞就分布在 6 个不同的 C++ 文件中，这类样本能够训练模型理解跨文件、跨函数的漏洞场景。  
  
这种在代码规模上的刻意区分非常重要。已有研究表明，代码越长、结构越复杂，漏洞分析的难度通常也越高，而在训练阶段引入这类“困难样本”，有助于显著提升模型在真实场景下的表现。  
  
最后，在正式训练之前，我们对所有数据进行了  
去重和去污染处理  
，移除重复样本，并确保训练数据中不包含测试集内容，从而避免数据泄露，保证评估结果的可靠性。  
  
下表是详细信息。  
  
![](https://mmbiz.qpic.cn/sz_mmbiz_png/rhmRSVBNbicrtc5Epcy72SASXUpnqU1Ly8ckfeEl211NwZlpicVWNGbfia6BLMGsxO1asYfHicaTiaiapBekTIBcEaOQ/640?wx_fmt=png&from=appmsg "")  
  
![]( "")  
![]( "")  
![]( "")  
  
04  
  
训练过程  
  
  
  
![](https://mmbiz.qpic.cn/sz_mmbiz_png/rhmRSVBNbicpQscUKCBoKtGjiaiaBatb6cx0lAoPicOicYeWaxDArvHmjmP1yVpOPQESVOyf5xRTKMzCOEPbax2mwwg/640?from=appmsg "")  
![]( "")  
![]( "")  
![]( "")  
  
在训练过程中，我们的目标不是简单提升漏洞识别准确率，而是让模型学会  
稳定、可解释地进行安全分析推理  
。因此，训练流程围绕高质量推理数据的生成、筛选和校准展开。  
  
如上图，在原始数据处理完成后（最左侧框），开始训练准备。  
  
首先，我们使用两个当前最先进的开源推理模型   
DeepSeek-R1  
 和   
QwQ-32B  
 作为教师模型，生成训练所需的推理数据。选择这两个模型，一方面是为了验证仅依赖开源模型生成的数据，也可以训练出能力不逊于商业模型的推理模型；另一方面，这两个模型在推理风格上存在差异，对假阳性和假阴性的偏好不同。将二者生成的数据混合使用，有助于在训练阶段平衡不同类型的误判，同时避免模型在监督微调过程中出现输出退化的问题。  
  
随后，我们对生成的推理数据进行严格过滤。首先剔除推理过程过长、包含大量冗余步骤的样本，以提高训练效率；其次过滤掉最终结论明显错误的数据。在漏洞分析任务中，小模型不仅需要学习推理结构，更需要掌握正确的安全知识，因此错误结论会对训练产生负面影响。  
  
但单纯的拒绝采样会显著减少可用数据量。为此，我们引入了一种基于规则的纠错方法：针对教师模型在特定 CWE 上的常见失败场景，附加额外的分析指引重新生成推理结果。例如，在路径遍历漏洞中，明确要求模型检查路径规范化、目录遍历序列以及访问目录限制，从而修正原本不可靠的推理数据。  
  
在此基础上，我们进一步引入基于摘要的二次训练，让教师模型对自身推理进行压缩总结，并使用这些更简洁的推理样本对模型进行校准训练，使模型在保持性能的同时，输出更加克制、易读的分析结果。  
  
在测试阶段，我们采用截断生成和基于策略的生成方式，以提升推理效率并降低任务复杂度，从而获得更加稳定的漏洞判断结果。  
  
  
05  
  
总结  
  
  
  
漏洞处理是安全领域中最核心、也最具现实价值的工作之一，从软件供应链安全、漏洞扫描器到渗透测试，都存在着广泛而成熟的应用场景。  
  
VulnLLM-R 是专为漏洞检测设计的推理型语言模型。论文中的实验结果表明，该模型在多种测试场景下都表现出了显著优于通用模型和传统工具的检测效果。基于这一模型，作者进一步构建了一个以推理模型为核心的漏洞检测智能体（agent scaffold），并在真实开源项目中验证了其在项目级漏洞发现上的能力，最终发现并报告了 15 个此前未知的零日漏洞。  
  
这一工作为漏洞检测提供了一条清晰且前景可观的新路径：以安全专用工具和任务为核心构建智能体，再利用智能体产生的高质量推理数据反向训练专用模型，从而形成正向循环。  
  
这篇论文，一方面说明漏洞专用模型这条路是通的，值得发展。同时，其数据，训练方法，模型均已开源，无疑会推动这个领域快速进步。  
  
结合Novee的小模型看，这个领域前景广阔。  
  
  
论文地址：  
  
https://arxv.org/html/2512.07533v1  
  
开源地址：  
  
https://github.com/ucsb-mlsec/VulnLLM-R  
  
推荐阅读  
  
[](https://mp.weixin.qq.com/s?__biz=Mzg5NTMxMjQ4OA==&mid=2247486546&idx=1&sn=7cb63722670b663e50297d4b2dc874ad&scene=21#wechat_redirect)  
  
[安全垂类小模型效果能超过大模型？看看以色列Novee的效果](https://mp.weixin.qq.com/s?__biz=Mzg5NTMxMjQ4OA==&mid=2247486546&idx=1&sn=7cb63722670b663e50297d4b2dc874ad&scene=21#wechat_redirect)  
  
  
  
  
  
